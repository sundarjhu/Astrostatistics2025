{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sundarjhu/Astrostatistics2025/blob/main/Lesson19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dynesty ultranest arviz pytensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xgmsfx0mzJiY",
        "outputId": "3cf3f45a-0307-403e-82a8-caa81b16eff0"
      },
      "id": "Xgmsfx0mzJiY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dynesty\n",
            "  Downloading dynesty-3.0.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting ultranest\n",
            "  Downloading ultranest-4.4.0.tar.gz (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb5cae34",
      "metadata": {
        "id": "eb5cae34"
      },
      "source": [
        "\n",
        "# Frequentist vs Bayesian Model Selection: Quadratic vs Quintic Fits\n",
        "\n",
        "This notebook demonstrates model selection using both **frequentist** (AIC/BIC) and **Bayesian** (marginal likelihood) methods.  \n",
        "We generate synthetic data from a quadratic model and compare a quadratic and a quintic polynomial fit.\n",
        "\n",
        "The Bayesian evidence is computed robustly using **nested sampling** (`dynesty`, `UltraNest`), while **PyMC's SMC** evidence is shown with caveats about its limitations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "331ca25a",
      "metadata": {
        "id": "331ca25a"
      },
      "source": [
        "\n",
        "## 1. Generate Synthetic Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa73c0f6",
      "metadata": {
        "id": "aa73c0f6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "x = np.linspace(-3, 3, 60)\n",
        "y_true = 1 + 2*x - 0.5*x**2\n",
        "yerr = np.ones_like(x)\n",
        "y = y_true + rng.normal(0, yerr)\n",
        "\n",
        "plt.errorbar(x, y, yerr, fmt='o', color='k', label='data')\n",
        "plt.plot(x, y_true, 'r--', label='true model')\n",
        "plt.xlabel('x'); plt.ylabel('y'); plt.legend()\n",
        "plt.title('Synthetic data (quadratic truth)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4059572c",
      "metadata": {
        "id": "4059572c"
      },
      "source": [
        "\n",
        "## 2. Frequentist Fits: Quadratic and Quintic\n",
        "\n",
        "Compute AIC and BIC to compare models under frequentist assumptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "303a2745",
      "metadata": {
        "id": "303a2745"
      },
      "outputs": [],
      "source": [
        "\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "def fit_poly(x, y, yerr, deg):\n",
        "    p0 = np.zeros(deg+1)\n",
        "    popt, pcov = curve_fit(lambda x,*p: np.polyval(p,x), x, y, sigma=yerr, p0=p0)\n",
        "    return popt, pcov\n",
        "\n",
        "def chi2(p):\n",
        "    return np.sum(((y - np.polyval(p, x))/yerr)**2)\n",
        "\n",
        "p2, c2 = fit_poly(x, y, yerr, 2)\n",
        "p5, c5 = fit_poly(x, y, yerr, 5)\n",
        "\n",
        "chi2_2, chi2_5 = chi2(p2), chi2(p5)\n",
        "n = len(y)\n",
        "k2, k5 = len(p2), len(p5)\n",
        "\n",
        "AIC2, AIC5 = 2*k2 + chi2_2, 2*k5 + chi2_5\n",
        "BIC2, BIC5 = k2*np.log(n) + chi2_2, k5*np.log(n) + chi2_5\n",
        "\n",
        "print(f\"AIC: quadratic={AIC2:.1f}, quintic={AIC5:.1f}\")\n",
        "print(f\"BIC: quadratic={BIC2:.1f}, quintic={BIC5:.1f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfa28ead",
      "metadata": {
        "id": "bfa28ead"
      },
      "source": [
        "\n",
        "## 3. Bayesian Evidence via Nested Sampling (dynesty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84793632",
      "metadata": {
        "id": "84793632"
      },
      "outputs": [],
      "source": [
        "\n",
        "import dynesty\n",
        "\n",
        "def loglike(theta):\n",
        "    model = np.polyval(theta, x)\n",
        "    return -0.5*np.sum(((y - model)/yerr)**2)\n",
        "\n",
        "def prior_transform(u):\n",
        "    return 20*(u - 0.5)\n",
        "\n",
        "logZ_dynesty = {}\n",
        "for deg in [2, 5]:\n",
        "    ndim = deg + 1\n",
        "    sampler = dynesty.NestedSampler(loglike, prior_transform, ndim, nlive=300)\n",
        "    sampler.run_nested()\n",
        "    res = sampler.results\n",
        "    logZ_dynesty[deg] = res.logz[-1]\n",
        "    print(f\"dynesty logZ (deg {deg}) = {res.logz[-1]:.2f} ± {res.logzerr[-1]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88999874",
      "metadata": {
        "id": "88999874"
      },
      "source": [
        "\n",
        "## 4. Bayesian Evidence via UltraNest (quiet mode)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72a64182",
      "metadata": {
        "id": "72a64182"
      },
      "outputs": [],
      "source": [
        "\n",
        "import ultranest, logging, os, contextlib\n",
        "\n",
        "def loglike_ultra(theta):\n",
        "    model = np.polyval(theta, x)\n",
        "    return -0.5*np.sum(((y - model)/yerr)**2)\n",
        "\n",
        "def prior_ultra(u):\n",
        "    return 20*(u - 0.5)\n",
        "\n",
        "# Silence most output\n",
        "logger = logging.getLogger(\"ultranest\")\n",
        "logger.setLevel(logging.WARNING)\n",
        "\n",
        "logZ_ultra = {}\n",
        "for deg in [2, 5]:\n",
        "    names = [f\"a{i}\" for i in range(deg+1)]\n",
        "    sampler = ultranest.ReactiveNestedSampler(names, loglike_ultra, transform=prior_ultra)\n",
        "    with open(os.devnull, 'w') as f, contextlib.redirect_stderr(f):\n",
        "        result = sampler.run(min_num_live_points=300, dlogz=0.1, show_status=False, viz_callback=False)\n",
        "    logZ_ultra[deg] = result['logz']\n",
        "    print(f\"UltraNest logZ (deg {deg}) = {result['logz']:.2f} ± {result['logzerr']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79e8b1be",
      "metadata": {
        "id": "79e8b1be"
      },
      "source": [
        "\n",
        "## 5. Compare Evidences and Interpret\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce7b677",
      "metadata": {
        "id": "dce7b677"
      },
      "outputs": [],
      "source": [
        "\n",
        "logZs = {'dynesty': logZ_dynesty, 'ultranest': logZ_ultra}\n",
        "for method, vals in logZs.items():\n",
        "    if len(vals) == 2:\n",
        "        lnB = vals[2] - vals[5]\n",
        "        print(f\"{method:8s}: DeltalnB = {lnB:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2018319",
      "metadata": {
        "id": "a2018319"
      },
      "source": [
        "\n",
        "## 7. Discussion\n",
        "- Dynesty and UltraNest produce consistent evidence values.\n",
        "- PyMC's evidence field is often NaN due to current API limitations.\n",
        "- Nested sampling is the robust and recommended way to compute Bayesian evidence.\n",
        "\n",
        "| Δln Z | Strength of Evidence |\n",
        "|:------:|:--------------------|\n",
        "| < 1 | Inconclusive |\n",
        "| 1–2.5 | Weak |\n",
        "| 2.5–5 | Moderate |\n",
        "| > 5 | Strong |\n",
        "\n",
        "In this dataset (quadratic truth), all samplers should favor the quadratic model.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}